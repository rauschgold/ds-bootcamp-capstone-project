{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2013-2017 data \n",
    "I create a copy of each dataset for \"safety\" reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014 = pd.read_csv(\"../data/transp_org_14_17/df_2014.csv\", encoding='iso8859_2')\n",
    "df_2014_copy_01 = df_2014.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing exempt by NaN **'yearly_budget'**, **'yearly_forecast'**, **'wlc_baseline_incl_NCG'**\n",
    "### 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014_copy_01['yearly_budget'] = pd.to_numeric(df_2014_copy_01['yearly_budget'], errors='coerce')\n",
    "df_2014_copy_01['yearly_forecast'] = pd.to_numeric(df_2014_copy_01['yearly_forecast'], errors='coerce')\n",
    "df_2014_copy_01['wlc_baseline_incl_NCG'] = pd.to_numeric(df_2014_copy_01['wlc_baseline_incl_NCG'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015 = pd.read_csv(\"../data/transp_org_14_17/df_2015.csv\", encoding='iso8859_2')\n",
    "df_2015_copy_01 = df_2015.copy()\n",
    "#df_2015_copy_01.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly_budget\n",
    "# Specify the word you want to look for\n",
    "special_word_1= 'Data'\n",
    "special_word_2 = 'Exempt'\n",
    "# Replace entries containing the special word with NaN\n",
    "df_2015_copy_01['yearly_budget'] = df_2015_copy_01['yearly_budget'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2015_copy_01['yearly_budget'] = df_2015_copy_01['yearly_budget'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2015_copy_01['yearly_budget'] = df_2015_copy_01['yearly_budget'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "# yearly_forecast'\n",
    "df_2015_copy_01['yearly_forecast'] = df_2015_copy_01['yearly_forecast'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2015_copy_01['yearly_forecast'] = df_2015_copy_01['yearly_forecast'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2015_copy_01['yearly_forecast'] = df_2015_copy_01['yearly_forecast'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "#wlc_baseline_incl_NCG\n",
    "df_2015_copy_01['wlc_baseline_incl_NCG'] = df_2015_copy_01['wlc_baseline_incl_NCG'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2015_copy_01['wlc_baseline_incl_NCG'] = df_2015_copy_01['wlc_baseline_incl_NCG'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2015_copy_01['wlc_baseline_incl_NCG'] = df_2015_copy_01['wlc_baseline_incl_NCG'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = pd.read_csv(\"../data/transp_org_14_17/df_2016.csv\", encoding='iso8859_2')\n",
    "df_2016_copy_01 = df_2016.copy()\n",
    "#df_2016_copy_01.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly_budget\n",
    "# Specify the word you want to look for\n",
    "special_word_1= 'Data'\n",
    "special_word_2 = 'Exempt'\n",
    "# Replace entries containing the special word with NaN\n",
    "df_2016_copy_01['yearly_budget'] = df_2016_copy_01['yearly_budget'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2016_copy_01['yearly_budget'] = df_2016_copy_01['yearly_budget'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2016_copy_01['yearly_budget'] = df_2016_copy_01['yearly_budget'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "# yearly_forecast'\n",
    "df_2016_copy_01['yearly_forecast'] = df_2016_copy_01['yearly_forecast'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2016_copy_01['yearly_forecast'] = df_2016_copy_01['yearly_forecast'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2016_copy_01['yearly_forecast'] = df_2016_copy_01['yearly_forecast'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "#wlc_baseline_incl_NCG\n",
    "df_2016_copy_01['wlc_baseline_incl_NCG'] = df_2016_copy_01['wlc_baseline_incl_NCG'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2016_copy_01['wlc_baseline_incl_NCG'] = df_2016_copy_01['wlc_baseline_incl_NCG'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2016_copy_01['wlc_baseline_incl_NCG'] = df_2016_copy_01['wlc_baseline_incl_NCG'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = pd.read_csv(\"../data/transp_org_14_17/df_2017.csv\", encoding='iso8859_2')\n",
    "df_2017 = df_2017.drop('Unnamed: 15', axis=1)\n",
    "#df_2017.columns\n",
    "df_2017_copy_01 = df_2017.copy()\n",
    "#df_2017_copy_01.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly_budget\n",
    "# Specify the word you want to look for\n",
    "special_word_1= 'Data'\n",
    "special_word_2 = 'Exempt'\n",
    "# Replace entries containing the special word with NaN\n",
    "df_2017_copy_01['yearly_budget'] = df_2017_copy_01['yearly_budget'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2017_copy_01['yearly_budget'] = df_2017_copy_01['yearly_budget'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2017_copy_01['yearly_budget'] = df_2017_copy_01['yearly_budget'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "# yearly_forecast'\n",
    "df_2017_copy_01['yearly_forecast'] = df_2017_copy_01['yearly_forecast'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2017_copy_01['yearly_forecast'] = df_2017_copy_01['yearly_forecast'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2017_copy_01['yearly_forecast'] = df_2017_copy_01['yearly_forecast'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "#wlc_baseline_incl_NCG\n",
    "df_2017_copy_01['wlc_baseline_incl_NCG'] = df_2017_copy_01['wlc_baseline_incl_NCG'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2017_copy_01['wlc_baseline_incl_NCG'] = df_2017_copy_01['wlc_baseline_incl_NCG'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2017_copy_01['wlc_baseline_incl_NCG'] = df_2017_copy_01['wlc_baseline_incl_NCG'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging New data 2014-2017 together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014_2017_copy_01 = pd.concat([df_2014_copy_01, df_2015_copy_01, df_2016_copy_01, df_2017_copy_01], axis=0)\n",
    "#df_2014_2017_copy_01\n",
    "df_2014_2017_copy_01.to_csv('df_2014_2017_copy_01.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Colour rating column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace entries containing the special word with NaN\n",
    "special_word_3 ='exempt'\n",
    "special_word_4 ='No DCA'\n",
    "df_2014_2017_copy_01['colour_rating'] = df_2014_2017_copy_01['colour_rating'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2014_2017_copy_01['colour_rating'] = df_2014_2017_copy_01['colour_rating'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2014_2017_copy_01['colour_rating'] = df_2014_2017_copy_01['colour_rating'].apply(lambda x: np.nan if isinstance(x, str) and special_word_3 in x else x)\n",
    "df_2014_2017_copy_01['colour_rating'] = df_2014_2017_copy_01['colour_rating'].apply(lambda x: np.nan if isinstance(x, str) and special_word_4 in x else x)\n",
    "#remove the spaces \n",
    "df_2014_2017_copy_01['colour_rating'] = df_2014_2017_copy_01['colour_rating'].str.replace(r'\\s+', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start date and end date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2014_2017_copy_01['start_date'].unique()\n",
    "#df_2014_2017_copy_01['end_date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start date column\n",
    "df_2014_2017_copy_01['start_date'] = df_2014_2017_copy_01['start_date'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2014_2017_copy_01['start_date'] = df_2014_2017_copy_01['start_date'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "\n",
    "#end date column\n",
    "df_2014_2017_copy_01['end_date'] = df_2014_2017_copy_01['end_date'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2014_2017_copy_01['end_date'] = df_2014_2017_copy_01['end_date'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning: start and end date column have some odd format data or text. the following function will find where the odds are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start date column\n",
    "# Function to identify incorrectly formatted dates\n",
    "def find_odd_entries(df_2014_2017_copy_01, start_date):\n",
    "    odd_entries = []  # List to store odd entries and their positions\n",
    "    \n",
    "    for index, value in df_2014_2017_copy_01[start_date].items():\n",
    "        try:\n",
    "            # Attempt to convert to datetime with the expected format\n",
    "            pd.to_datetime(value, format='%d/%m/%Y')\n",
    "        except ValueError:\n",
    "            # If conversion fails, add the entry and its index to the list\n",
    "            odd_entries.append((index, value))\n",
    "    \n",
    "    return odd_entries\n",
    "\n",
    "# Use the function to find odd entries in the specified column\n",
    "odd_entries_list = find_odd_entries(df_2014_2017_copy_01, 'start_date')\n",
    "\n",
    "\n",
    "# Display the list of odd entries with their positions\n",
    "print(\"Odd entries with their positions:\")\n",
    "for idx, entry in odd_entries_list:\n",
    "    print(f\"Position: {idx}, Entry: {entry}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end date column\n",
    "# Function to identify incorrectly formatted dates\n",
    "def find_odd_entries_end(df_2014_2017_copy_01, end_date):\n",
    "    odd_entries_end = []  # List to store odd entries and their positions\n",
    "    \n",
    "    for index, value in df_2014_2017_copy_01[end_date].items():\n",
    "        try:\n",
    "            # Attempt to convert to datetime with the expected format\n",
    "            pd.to_datetime(value, format='%d/%m/%Y')\n",
    "        except ValueError:\n",
    "            # If conversion fails, add the entry and its index to the list\n",
    "            odd_entries_end.append((index, value))\n",
    "    \n",
    "    return odd_entries_end\n",
    "\n",
    "# Use the function to find odd entries in the specified column\n",
    "odd_entries_list_end = find_odd_entries_end(df_2014_2017_copy_01, 'end_date')\n",
    "\n",
    "\n",
    "# Display the list of odd entries with their positions\n",
    "print(\"Odd entries with their positions:\")\n",
    "for idx, entry in odd_entries_list_end:\n",
    "    print(f\"Position: {idx}, Entry: {entry}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Down below I tried to fix the problem with start date but it did not work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problematic_entry  position :563,\n",
    "problematic_entry = df_2014_2017_copy_01.iloc[563]['start_date']\n",
    "print(problematic_entry)\n",
    "\n",
    "#problematic_entry_2 = df_2014_2017_copy_01.iloc[563]['end_date']\n",
    "#print(problematic_entry_2)\n",
    "\n",
    "df_2014_2017_copy_01.at[563, 'start_date'] = '01/12/2014'\n",
    "\n",
    "roblematic_entry_solv = df_2014_2017_copy_01.iloc[563]['start_date']\n",
    "roblematic_entry_solv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014_2017_copy_01 = df_2014_2017_copy_01.drop(\"Unnamed: 0\", axis=1)\n",
    "df_2014_2017_copy_01['start_date'] = df_2014_2017_copy_01['start_date'].str.replace('\\n', '', regex=False).str.replace('1/012/2014', \"01/12/2014\")\n",
    "df_2014_2017_copy_01['end_date'] = df_2014_2017_copy_01['end_date'].str.replace('\\n', '', regex=False)\n",
    "\n",
    "df_2014_2017_copy_01['start_date'] = pd.to_datetime(df_2014_2017_copy_01['start_date'], format='%d/%m/%Y', errors=\"coerce\")\n",
    "df_2014_2017_copy_01['end_date'] = pd.to_datetime(df_2014_2017_copy_01['end_date'], format='%d/%m/%Y', errors=\"coerce\")\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "#df_2014_2017_copy_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014_2017_copy_01.to_pickle(\"../data/pickle/cleaned_2014-2017.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---\n",
    "### Old concat data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old dataset\n",
    "df_2014_2017 = pd.concat([df_2014, df_2015, df_2016, df_2017], axis=0)\n",
    "df_2014_2017.to_csv('df_2014_2017.csv', index=False)\n",
    "# old dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA 02 \n",
    "Cleaning up department name:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['project_name', 'department', 'colour_rating', 'description_aims',\n",
       "       'rating_comment', 'start_date', 'end_date', 'schedule_comment',\n",
       "       'yearly_budget', 'yearly_forecast', 'wlc_baseline_incl_NCG',\n",
       "       'variance_comment', 'budget_comment', 'year', 'report_category',\n",
       "       'project_number', 'total_benefits', 'benefits_comment', 'GDP',\n",
       "       'annual_earning_ft', 'unemployment_rate', 'youth_unemployment_rate',\n",
       "       'inflation_rate', 'population', 'gov_debt', 'tax_revenue',\n",
       "       'revenue_excl_grants', 'grants_and_other_revenue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_02 = pd.read_pickle('../data/pickle/ready_for_EDA.pkl')\n",
    "df_02.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_02['department'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CO', 'DBT', 'DCMS', 'DEFRA', 'DESNZ', 'DFE', 'DFT', 'DHSC',\n",
       "       'DLUHC', 'DSIT', 'DWP', 'FCDO', 'HMLR', 'HMRC', 'HMT', 'HO', 'MOD',\n",
       "       'MOJ', 'NCA', 'ONS', 'VOA', 'BEIS', 'DEFRA & DFT', 'MHCLG', 'DFID',\n",
       "       'FCO', 'BIS', 'DCLG', 'DECC', 'DOH', 'NS&I', 'CPS',\n",
       "       'DOH NON CAPITAL', 'DOH CAPITAL', 'DH'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_02['department'] = df_02['department'].str.upper()\n",
    "df_02['department'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some departments changes their names name along the time, with new government for example.\n",
    "To merge :\n",
    "- `DoH`/`DHSC` Department of Health/ Department for Health & Social Care (formerly DH)\n",
    "\n",
    " 'DOH NON CAPITAL', 'DOH CAPITAL'  this differentiation in the category appeared only in 2015. \n",
    "\n",
    "**DOH CAPITAL**: Likely relates to funds or projects involving infrastructure, equipment, or other capital assets.\n",
    "**DOH NON CAPITAL**: Pertains to day-to-day operational costs, services, and ongoing activities.\n",
    "\n",
    "- `FCO`/`FCDO`Foreign and Commonwealth Office / Foreign, Commonwealth and Development Office \n",
    "\n",
    "- `MHCLG` Ministry of Housing, Communities and Local Government\n",
    "- `DLUHC` Department for Levelling Up, Housing and Communities \n",
    "- `DCLG` Department for Communities and Local Government\n",
    "\n",
    "**DCLG → MHCLG → DLUHC**: These departments are direct continuations of each other, with each rebranding reflecting changes in focus or priority\n",
    "\n",
    "- `DESNZ` Department for Energy Security and Net Zero ( created on 7 February 2023)\n",
    "- `BEIS` Department for Business, Energy and Industrial Strategy \n",
    "- `DECC` Department of Energy and Climate Change\n",
    "\n",
    "**DECC → BEIS → DESNZ**: DECC’s responsibilities were absorbed into BEIS in 2016, which was later split, leading to the creation of DESNZ in 2023. These changes reflect evolving government focus, particularly on energy security and climate issues\n",
    "\n",
    "\n",
    "- `BIS` Department for Business, Innovation and Skills \n",
    "(Founded: June 5, 2009 Dissolved: 14 July 2016)\n",
    "- `DSIT` Department for Science, Innovation & Technology \n",
    " (Formed: 7 February 2023)\n",
    "\n",
    "**BIS → BEIS → DSIT**: The dissolution of BIS in 2016 and the creation of BEIS led to a broader department that combined energy, business, and innovation. With the 2023 restructuring, DSIT was formed to specifically focus on science, innovation, and technology, carving out these responsibilities from BEIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Create a dictionary mapping variations to the unified name\n",
    "unify_map = {\n",
    "    'DOH': 'DHSC',\n",
    "    'DH':'DHSC',\n",
    "    'DOH NON CAPITAL':'DHSC',\n",
    "    'DOH CAPITAL':'DHSC',\n",
    "    'FCO': 'FCDO',\n",
    "    'DCLG':'DLUHC',\n",
    "    'MHCLG':'DLUHC',\n",
    "    'DECC':'DESNZ',\n",
    "    'BEIS':'DESNZ',\n",
    "    'BIs':'DSIT',\n",
    "}\n",
    "\n",
    "# Replace the variations with the unified name\n",
    "df_02['department'] = df_02['department'].replace(unify_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "department\n",
       "MOD            393\n",
       "DHSC           175\n",
       "MOJ            170\n",
       "DFT            168\n",
       "HO             122\n",
       "DESNZ          118\n",
       "HMRC            95\n",
       "CO              85\n",
       "DWP             65\n",
       "DFE             62\n",
       "DCMS            57\n",
       "DEFRA           52\n",
       "FCDO            41\n",
       "DLUHC           31\n",
       "ONS             24\n",
       "BIS             24\n",
       "NCA             13\n",
       "DSIT             7\n",
       "DFID             7\n",
       "HMT              5\n",
       "DBT              3\n",
       "HMLR             3\n",
       "CPS              3\n",
       "NS&I             2\n",
       "VOA              1\n",
       "DEFRA & DFT      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_02['department'].nunique())\n",
    "df_02['department'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "#df_02.query(\"department == 'DOH NON CAPITAL'\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "doh_rows = df_02[df_02['department'] == 'DOH CAPITAL']\n",
    "#doh_rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
