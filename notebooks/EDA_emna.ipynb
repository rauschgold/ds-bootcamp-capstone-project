{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook contains  2013-2017 data\n",
    "I create a copy of each dataset for \"safety\" reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014 = pd.read_csv(\"../data/transp_org_14_17/df_2014.csv\", encoding='iso8859_2')\n",
    "df_2014_copy_01 = df_2014.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing exempt by NaN **'yearly_budget'**, **'yearly_forecast'**, **'wlc_baseline_incl_NCG'**\n",
    "## 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014_copy_01['yearly_budget'] = pd.to_numeric(df_2014_copy_01['yearly_budget'], errors='coerce')\n",
    "df_2014_copy_01['yearly_forecast'] = pd.to_numeric(df_2014_copy_01['yearly_forecast'], errors='coerce')\n",
    "df_2014_copy_01['wlc_baseline_incl_NCG'] = pd.to_numeric(df_2014_copy_01['wlc_baseline_incl_NCG'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015 = pd.read_csv(\"../data/transp_org_14_17/df_2015.csv\", encoding='iso8859_2')\n",
    "df_2015_copy_01 = df_2015.copy()\n",
    "#df_2015_copy_01.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly_budget\n",
    "# Specify the word you want to look for\n",
    "special_word_1= 'Data'\n",
    "special_word_2 = 'Exempt'\n",
    "# Replace entries containing the special word with NaN\n",
    "df_2015_copy_01['yearly_budget'] = df_2015_copy_01['yearly_budget'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2015_copy_01['yearly_budget'] = df_2015_copy_01['yearly_budget'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2015_copy_01['yearly_budget'] = df_2015_copy_01['yearly_budget'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "# yearly_forecast'\n",
    "df_2015_copy_01['yearly_forecast'] = df_2015_copy_01['yearly_forecast'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2015_copy_01['yearly_forecast'] = df_2015_copy_01['yearly_forecast'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2015_copy_01['yearly_forecast'] = df_2015_copy_01['yearly_forecast'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "#wlc_baseline_incl_NCG\n",
    "df_2015_copy_01['wlc_baseline_incl_NCG'] = df_2015_copy_01['wlc_baseline_incl_NCG'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2015_copy_01['wlc_baseline_incl_NCG'] = df_2015_copy_01['wlc_baseline_incl_NCG'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2015_copy_01['wlc_baseline_incl_NCG'] = df_2015_copy_01['wlc_baseline_incl_NCG'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = pd.read_csv(\"../data/transp_org_14_17/df_2016.csv\", encoding='iso8859_2')\n",
    "df_2016_copy_01 = df_2016.copy()\n",
    "#df_2016_copy_01.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly_budget\n",
    "# Specify the word you want to look for\n",
    "special_word_1= 'Data'\n",
    "special_word_2 = 'Exempt'\n",
    "# Replace entries containing the special word with NaN\n",
    "df_2016_copy_01['yearly_budget'] = df_2016_copy_01['yearly_budget'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2016_copy_01['yearly_budget'] = df_2016_copy_01['yearly_budget'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2016_copy_01['yearly_budget'] = df_2016_copy_01['yearly_budget'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "# yearly_forecast'\n",
    "df_2016_copy_01['yearly_forecast'] = df_2016_copy_01['yearly_forecast'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2016_copy_01['yearly_forecast'] = df_2016_copy_01['yearly_forecast'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2016_copy_01['yearly_forecast'] = df_2016_copy_01['yearly_forecast'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "#wlc_baseline_incl_NCG\n",
    "df_2016_copy_01['wlc_baseline_incl_NCG'] = df_2016_copy_01['wlc_baseline_incl_NCG'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2016_copy_01['wlc_baseline_incl_NCG'] = df_2016_copy_01['wlc_baseline_incl_NCG'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2016_copy_01['wlc_baseline_incl_NCG'] = df_2016_copy_01['wlc_baseline_incl_NCG'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = pd.read_csv(\"../data/transp_org_14_17/df_2017.csv\", encoding='iso8859_2')\n",
    "df_2017 = df_2017.drop('Unnamed: 15', axis=1)\n",
    "#df_2017.columns\n",
    "df_2017_copy_01 = df_2017.copy()\n",
    "#df_2017_copy_01.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly_budget\n",
    "# Specify the word you want to look for\n",
    "special_word_1= 'Data'\n",
    "special_word_2 = 'Exempt'\n",
    "# Replace entries containing the special word with NaN\n",
    "df_2017_copy_01['yearly_budget'] = df_2017_copy_01['yearly_budget'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2017_copy_01['yearly_budget'] = df_2017_copy_01['yearly_budget'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2017_copy_01['yearly_budget'] = df_2017_copy_01['yearly_budget'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "# yearly_forecast'\n",
    "df_2017_copy_01['yearly_forecast'] = df_2017_copy_01['yearly_forecast'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2017_copy_01['yearly_forecast'] = df_2017_copy_01['yearly_forecast'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2017_copy_01['yearly_forecast'] = df_2017_copy_01['yearly_forecast'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "#wlc_baseline_incl_NCG\n",
    "df_2017_copy_01['wlc_baseline_incl_NCG'] = df_2017_copy_01['wlc_baseline_incl_NCG'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2017_copy_01['wlc_baseline_incl_NCG'] = df_2017_copy_01['wlc_baseline_incl_NCG'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2017_copy_01['wlc_baseline_incl_NCG'] = df_2017_copy_01['wlc_baseline_incl_NCG'].str.extract(r'(\\d+\\.\\d+|\\d+)').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging New data 2014-2017 together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014_2017_copy_01 = pd.concat([df_2014_copy_01, df_2015_copy_01, df_2016_copy_01, df_2017_copy_01], axis=0)\n",
    "#df_2014_2017_copy_01\n",
    "df_2014_2017_copy_01.to_csv('df_2014_2017_copy_01.csv', index=False)\n",
    "df_2014_2017_copy_01.to_csv('df_2014_2017_copy_01.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Colour rating column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace entries containing the special word with NaN\n",
    "special_word_3 ='exempt'\n",
    "special_word_4 ='No DCA'\n",
    "df_2014_2017_copy_01['colour_rating'] = df_2014_2017_copy_01['colour_rating'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2014_2017_copy_01['colour_rating'] = df_2014_2017_copy_01['colour_rating'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "df_2014_2017_copy_01['colour_rating'] = df_2014_2017_copy_01['colour_rating'].apply(lambda x: np.nan if isinstance(x, str) and special_word_3 in x else x)\n",
    "df_2014_2017_copy_01['colour_rating'] = df_2014_2017_copy_01['colour_rating'].apply(lambda x: np.nan if isinstance(x, str) and special_word_4 in x else x)\n",
    "#remove the spaces \n",
    "df_2014_2017_copy_01['colour_rating'] = df_2014_2017_copy_01['colour_rating'].str.replace(r'\\s+', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start date and end date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2014_2017_copy_01['start_date'].unique()\n",
    "#df_2014_2017_copy_01['end_date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start date column\n",
    "df_2014_2017_copy_01['start_date'] = df_2014_2017_copy_01['start_date'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2014_2017_copy_01['start_date'] = df_2014_2017_copy_01['start_date'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n",
    "\n",
    "#end date column\n",
    "df_2014_2017_copy_01['end_date'] = df_2014_2017_copy_01['end_date'].apply(lambda x: np.nan if isinstance(x, str) and special_word_1 in x else x)\n",
    "df_2014_2017_copy_01['end_date'] = df_2014_2017_copy_01['end_date'].apply(lambda x: np.nan if isinstance(x, str) and special_word_2 in x else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning: start and end date column have some odd format data or text. the following function will find where the odds are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odd entries with their positions:\n",
      "Position: 32, Entry: 1/012/2014\n"
     ]
    }
   ],
   "source": [
    "#start date column\n",
    "# Function to identify incorrectly formatted dates\n",
    "def find_odd_entries(df_2014_2017_copy_01, start_date):\n",
    "    odd_entries = []  # List to store odd entries and their positions\n",
    "    \n",
    "    for index, value in df_2014_2017_copy_01[start_date].items():\n",
    "        try:\n",
    "            # Attempt to convert to datetime with the expected format\n",
    "            pd.to_datetime(value, format='%d/%m/%Y')\n",
    "        except ValueError:\n",
    "            # If conversion fails, add the entry and its index to the list\n",
    "            odd_entries.append((index, value))\n",
    "    \n",
    "    return odd_entries\n",
    "\n",
    "# Use the function to find odd entries in the specified column\n",
    "odd_entries_list = find_odd_entries(df_2014_2017_copy_01, 'start_date')\n",
    "\n",
    "\n",
    "# Display the list of odd entries with their positions\n",
    "print(\"Odd entries with their positions:\")\n",
    "for idx, entry in odd_entries_list:\n",
    "    print(f\"Position: {idx}, Entry: {entry}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odd entries with their positions:\n",
      "Position: 101, Entry: Reset\n",
      "Position: 51, Entry: No end date\n",
      "Position: 55, Entry: No end date\n",
      "Position: 66, Entry: No end date\n",
      "Position: 73, Entry: No end date\n",
      "Position: 110, Entry: 31/12/2015\n",
      "\n",
      "Position: 130, Entry: Not Applicable\n",
      "Position: 168, Entry: No end date\n"
     ]
    }
   ],
   "source": [
    "# end date column\n",
    "# Function to identify incorrectly formatted dates\n",
    "def find_odd_entries_end(df_2014_2017_copy_01, end_date):\n",
    "    odd_entries_end = []  # List to store odd entries and their positions\n",
    "    \n",
    "    for index, value in df_2014_2017_copy_01[end_date].items():\n",
    "        try:\n",
    "            # Attempt to convert to datetime with the expected format\n",
    "            pd.to_datetime(value, format='%d/%m/%Y')\n",
    "        except ValueError:\n",
    "            # If conversion fails, add the entry and its index to the list\n",
    "            odd_entries_end.append((index, value))\n",
    "    \n",
    "    return odd_entries_end\n",
    "\n",
    "# Use the function to find odd entries in the specified column\n",
    "odd_entries_list_end = find_odd_entries_end(df_2014_2017_copy_01, 'end_date')\n",
    "\n",
    "\n",
    "# Display the list of odd entries with their positions\n",
    "print(\"Odd entries with their positions:\")\n",
    "for idx, entry in odd_entries_list_end:\n",
    "    print(f\"Position: {idx}, Entry: {entry}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# down below I tried to fix the problem with start date but it did not work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problematic_entry  position :563,\n",
    "problematic_entry = df_2014_2017_copy_01.iloc[563]['start_date']\n",
    "print(problematic_entry)\n",
    "\n",
    "#problematic_entry_2 = df_2014_2017_copy_01.iloc[563]['end_date']\n",
    "#print(problematic_entry_2)\n",
    "\n",
    "df_2014_2017_copy_01.at[563, 'start_date'] = '01/12/2014'\n",
    "\n",
    "roblematic_entry_solv = df_2014_2017_copy_01.iloc[563]['start_date']\n",
    "roblematic_entry_solv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014_2017_copy_01['start_date'] = pd.to_datetime(df_2014_2017_copy_01['start_date'], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----- \n",
    "### Old concat data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old dataset\n",
    "df_2014_2017 = pd.concat([df_2014, df_2015, df_2016, df_2017], axis=0)\n",
    "df_2014_2017.to_csv('df_2014_2017.csv', index=False)\n",
    "# old dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
