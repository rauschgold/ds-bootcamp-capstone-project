{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Project Costs in UK Public Sector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Motivation & Background Knowledge about Projects in UK Public Sector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting the Data & EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is retrieved through https://www.gov.uk/government/collections/major-projects-data that collects data from 2012-2022 about the progress of projects in the Government Major Projects Portfolio. For each year we can download a `.csv` file and after downloading all of them, we compare the columns in order to merge them together. These are stored in the folder `raw_data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Preparing & Merging `.csv` files into a Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we found out, the column names have been changed throughout the years and in order to merge the yearly file into one in the end, we first need to ensure the correct naming. We did this actually in Excel before loading the files into the Dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! We need to transpose some first and save them again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a Dicitionary to load and save the Dataframes\n",
    "dataframes = {}\n",
    "\n",
    "# Defining the path from which to load the .csv files\n",
    "base_path = '../data/raw_data/uk_'\n",
    "years = range(2014, 2024)\n",
    "\n",
    "# Function to load .csv files with different delimiters as we have different ones in the files\n",
    "def load_csv_with_fallback(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='iso-8859-2', delimiter=';')\n",
    "        return df\n",
    "    except pd.errors.ParserError:\n",
    "        return pd.read_csv(file_path, encoding='iso-8859-2', delimiter=',')\n",
    "\n",
    "# Loading .csv files into Dataframe and save into Dictionary\n",
    "for year in years:\n",
    "    file_path = f'{base_path}{year}.csv'\n",
    "    df_name = f'df_{year}'\n",
    "    dataframes[df_name] = load_csv_with_fallback(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the `.csv` files into separate Dataframes, we can merge them by concatinating as we also see that latest datasets have more columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that merges the dataframes to one dictionary\n",
    "def merge_dataframes(dataframes_dict):\n",
    "    # Extracting all DataFrames from the dictionary and saving them as list\n",
    "    df_list = list(dataframes_dict.values())\n",
    "    \n",
    "    # Concetinating all Dataframes to one\n",
    "    merged_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Calling the function to merge all Dataframes\n",
    "df = merge_dataframes(dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initially find two columns for the colour rating but per instance only one of them contains the needed information. So we combine these into one final column for the colour rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fraus\\AppData\\Local\\Temp\\ipykernel_17112\\2742557625.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['colour_rating_new'] = df['colour_rating'].combine_first(df['colour_rating.1'])\n"
     ]
    }
   ],
   "source": [
    "df['colour_rating_new'] = df['colour_rating'].combine_first(df['colour_rating.1'])\n",
    "df = df.drop(columns=['colour_rating', 'colour_rating.1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, there is some text or symbols that needs to be removed from numeric columns. We start with removing the currency symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns where the currency symbol needs to be removed\n",
    "columns_to_replace = [\n",
    "    'wlc_baseline_incl_NCG',\n",
    "    'total_baseline',\n",
    "    'forecast_incl_NGC',\n",
    "    'yearly_forecast',\n",
    "    'TOTAL Baseline Benefits (Łm)'\n",
    "]\n",
    "\n",
    "# Loop for removal of the sign\n",
    "for column in columns_to_replace:\n",
    "    df[column] = df[column].str.replace('Ł', '', regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we remove the ',' from the numeric columns that have a 1.000-separator and make sure, the values are in float format so we can process them as numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function for the process\n",
    "def process_value(value):\n",
    "    # Trying to convert the value into a float\n",
    "    try:\n",
    "        float(value)\n",
    "        return value\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    # Second step: Replace ',' with '' and try again to convert into float\n",
    "    try:\n",
    "        value = value.replace(',', '')\n",
    "        float(value)\n",
    "        return value\n",
    "    except (ValueError, AttributeError):\n",
    "        return np.nan\n",
    "\n",
    "# Using the function to process various columns at once\n",
    "columns_to_process = ['total_baseline', 'forecast_incl_NGC', 'wlc_baseline_incl_NCG', 'TOTAL Baseline Benefits (Łm)', 'yearly_forecast']\n",
    "df[columns_to_process] = df[columns_to_process].applymap(process_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Imputing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "missing dates, missing benefits etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Preps (needs to be updated with final df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import .csv file as Dataframe\n",
    "#df = pd.read_csv('../data/raw_data/2021_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a duration column to the Dataframe\n",
    "#df['duration'] = (df['end_date'] - df['start_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a variance column to the Dataframe\n",
    "#df['duration'] = (df['end_date'] - df['start_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the DataFrame by 'project_name' and 'year'\n",
    "df.sort_values(by=['project_name', 'year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Forecast Variance (Yearly Forecast - Previous Yearly Forecast)\n",
    "df['forecast_variance_prev_year'] = df.groupby('project_name')['yearly_forecast'].pct_change() * 100\n",
    "\n",
    "# Calculating Budget Variance (Yearly Forecast - Yearly Budget)\n",
    "df['forecast_variance_budget'] = ((df['yearly_forecast'] - df['yearly_budget']) / df['yearly_budget']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage change trend for each project\n",
    "df['forecast_percentage_change_prev_year_filled'] = df.groupby('project_name')['forecast_variance_prev_year'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['forecast_variance_prev_year'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Last Observation Carried Forward (LOCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCF forecast MSE: 495769.72430543805\n"
     ]
    }
   ],
   "source": [
    "# LOCF baseline-model for costs (Forecast) based on £\n",
    "# Approach: We are taking the last two instances\n",
    "\n",
    "# Creating the predicted values based on the LOCF-method\n",
    "df['forecast_pred'] = df['yearly_forecast'].shift(1)\n",
    "\n",
    "# There is no previous value for the first entry, so the predicted value remains NaN\n",
    "# The model ignores the first entry as it has no previous point\n",
    "\n",
    "# Calculating the errors for the baseline model\n",
    "mse_forecast = mean_squared_error(df['yearly_forecast'].iloc[1:], df['forecast_pred'].iloc[1:])\n",
    "\n",
    "print(f\"LOCF forecast MSE: {mse_forecast}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCF forecast MSE: 1084528.7616024816\n"
     ]
    }
   ],
   "source": [
    "# LOCF baseline-model for costs (Forecast) based on %\n",
    "# Approach: We are taking the last two instances\n",
    "\n",
    "# Creating the predicted values based on the LOCF-method\n",
    "df['forecast_pred_percentage'] = df['forecast_variance_prev_year'].shift(1)\n",
    "\n",
    "# There is no previous value for the first entry, so the predicted value remains NaN\n",
    "# The model ignores the first entry as it has no previous point\n",
    "\n",
    "df['forecast_pred_percentage'].fillna(0, inplace=True)\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Calculating the errors for the baseline model\n",
    "mse_forecast = mean_squared_error(df['forecast_variance_prev_year'].iloc[1:], df['forecast_pred_percentage'].iloc[1:])\n",
    "\n",
    "print(f\"LOCF forecast MSE: {mse_forecast}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Calculating Forecast based on Variance Percentage Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the last known forecast value and the trend of the percentage change\n",
    "last_forecast = df.groupby('project_name').last()['yearly_forecast']\n",
    "last_percentage_change = df.groupby('project_name').last()['forecast_percentage_change_prev_year_filled']\n",
    "\n",
    "# Calculating forecast for 2024\n",
    "predicted_forecast_2024 = last_forecast * (1 + last_percentage_change / 100)\n",
    "\n",
    "# Creating new DataFrame including 2024 data\n",
    "df_2024 = pd.DataFrame({\n",
    "    'project_name': last_forecast.index,\n",
    "    'year': 2024,\n",
    "    'predicted_forecast': predicted_forecast_2024\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy/MSE calculate based on past years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Mean/Median Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          project_name  year   \n",
      "0                      10,000 Additional Prison Places  2024  \\\n",
      "1    10,000 Additional Prison Places Programme - Es...  2024   \n",
      "2    10K Additional Prison Places Estate Expansion ...  2024   \n",
      "3    10K additional Prison places Women's Estate Ex...  2024   \n",
      "4             10k Additional Prison Places - New Build  2024   \n",
      "..                                                 ...   ...   \n",
      "335                Workplace and Facilities Management  2024   \n",
      "336                    YOI Education Services Retender  2024   \n",
      "337                     YOUTH JUSTICE REFORM PROGRAMME  2024   \n",
      "338                              Youth Investment Fund  2024   \n",
      "339                     Youth Justice Reform Programme  2024   \n",
      "\n",
      "     predicted_forecast_mean  predicted_forecast_median  \n",
      "0                  80.923483                        0.0  \n",
      "1                  80.923483                        0.0  \n",
      "2                  80.923483                        0.0  \n",
      "3                  80.923483                        0.0  \n",
      "4                  80.923483                        0.0  \n",
      "..                       ...                        ...  \n",
      "335                80.923483                        0.0  \n",
      "336                80.923483                        0.0  \n",
      "337                80.923483                        0.0  \n",
      "338                80.923483                        0.0  \n",
      "339                80.923483                        0.0  \n",
      "\n",
      "[340 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculating mean of 'forecast_variance_prev_year'\n",
    "mean_forecast = df['forecast_variance_prev_year'].mean()\n",
    "\n",
    "# Berechne den Median der Spalte 'yearly_forecast'\n",
    "median_forecast = df['forecast_variance_prev_year'].median()\n",
    "\n",
    "# Erstelle Vorhersagen für ein neues Jahr (z.B. 2024) basierend auf dem Mean und Median\n",
    "df['mean_forecast_prediction'] = mean_forecast\n",
    "df['median_forecast_prediction'] = median_forecast\n",
    "\n",
    "# Optional: Ergebnisse für das nächste Jahr in einem neuen DataFrame\n",
    "df_2024_1 = pd.DataFrame({\n",
    "    'project_name': df['project_name'].unique(),\n",
    "    'year': 2024,\n",
    "    'predicted_forecast_mean': mean_forecast,\n",
    "    'predicted_forecast_median': median_forecast\n",
    "})\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "print(df_2024_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train and test data\n",
    "y_train = \n",
    "y_test = \n",
    "\n",
    "# Mean Predictor\n",
    "mean_pred = np.mean(y_train)\n",
    "y_pred_mean = np.full(y_test.shape, mean_pred)\n",
    "\n",
    "# Median Predictor (optional)\n",
    "median_pred = np.median(y_train)\n",
    "y_pred_median = np.full(y_test.shape, median_pred)\n",
    "\n",
    "# Berechnung der Fehlermetrik (z.B. Mean Squared Error)\n",
    "mse_mean = mean_squared_error(y_test, y_pred_mean)\n",
    "mse_median = mean_squared_error(y_test, y_pred_median)\n",
    "\n",
    "print(f\"Mean Predictor MSE: {mse_mean}\")\n",
    "print(f\"Median Predictor MSE: {mse_median}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "duration, dummies, NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaling, pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Model 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
