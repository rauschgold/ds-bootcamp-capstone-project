{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just to hide things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_values = ['Amber', 'Green', 'Red', 'Amber/red', 'Amber/Green']\n",
    "result['colour_rating_new'] = result['colour_rating_new'].apply(lambda x: x if x in allowed_values else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.rename(columns={'colour_rating_new': 'colour_rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['yearly_forecast_new'] = result['yearly_forecast'].combine_first(result['forecast_incl_NGC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.drop(columns=['yearly_forecast', 'forecast_incl_NGC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.rename(columns={'yearly_forecast_new': 'yearly_forecast'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.drop(columns=['yearly_budget'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.rename(columns={'total_baseline': 'yearly_budget'})\n",
    "result = result.rename(columns={'TOTAL Baseline Benefits (Łm)': 'total_benefits'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = ['project_name','department','colour_rating','description_aims','rating_comment','start_date','end_date','schedule_comment','yearly_budget','yearly_forecast','wlc_baseline_incl_NCG','variance_comment','budget_comment','year','report_category','project_number','total_benefits','benefits_comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result[column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro = pd.read_csv('../data/macro/GDP.csv',encoding='iso-8859-2', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 1: Identifizieren der relevanten Zeilen\n",
    "remained_scheduled_df = df_franzi[df_franzi['schedule_comment'].str.contains('remained scheduled', case=False)]\n",
    "\n",
    "# Schritt 2: Aktuellsten 'end_date'-Wert für jedes 'project_name' ermitteln\n",
    "latest_end_dates = df_franzi.groupby('project_name').apply(lambda x: x.loc[x['year'].idxmax(), 'end_date'])\n",
    "\n",
    "# Schritt 3: Zuweisen des aktuellsten 'end_date' an die relevanten Zeilen\n",
    "for index, row in remained_scheduled_df.iterrows():\n",
    "    latest_end_date = latest_end_dates[row['project_name']]\n",
    "    if pd.isna(row['end_date']) and pd.notna(latest_end_date):\n",
    "        df_franzi.at[index, 'end_date'] = latest_end_date\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "df_franzi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schritt 2: Aktuellsten 'end_date'-Wert für jedes 'project_name' ermitteln\n",
    "latest_end_dates = df_franzi.groupby('project_name').apply(lambda x: x.loc[x['year'].idxmax(), 'start_date'])\n",
    "\n",
    "# Schritt 3: Zuweisen des aktuellsten 'end_date' an die relevanten Zeilen\n",
    "for index, row in remained_scheduled_df.iterrows():\n",
    "    latest_end_date = latest_end_dates[row['project_name']]\n",
    "    if pd.isna(row['start_date']) and pd.notna(latest_end_date):\n",
    "        df_franzi.at[index, 'start_date'] = latest_end_date\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "df_franzi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    month_mapping = {\n",
    "        'jan': '01', 'january': '01',\n",
    "        'feb': '02', 'february': '02',\n",
    "        'mar': '03', 'march': '03',\n",
    "        'apr': '04', 'april': '04',\n",
    "        'may': '05', 'may': '05',\n",
    "        'jun': '06', 'june': '06',\n",
    "        'jul': '07', 'july': '07',\n",
    "        'aug': '08', 'august': '08',\n",
    "        'sep': '09', 'september': '09',\n",
    "        'oct': '10', 'october': '10',\n",
    "        'nov': '11', 'november': '11',\n",
    "        'dec': '12', 'december': '12'\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_after_to_or_on(comment):\n",
    "    REGEX = \"(to|is|on)\\s*(\\d{1,2})\\s+(\\w+)\\s+(\\d{2,4})\"\n",
    "    x = re.compile(REGEX)\n",
    "    \n",
    "    match_REGEX = x.search(comment)      \n",
    "    \n",
    "    if match_REGEX:\n",
    "        day = match_REGEX.group(2)\n",
    "        month = match_REGEX.group(3)\n",
    "        year = match_REGEX.group(4)\n",
    "        if len(day) == 1:\n",
    "            day = '0'+ day\n",
    "        month = month_mapping.get(month.lower())\n",
    "        if len(year) == 2:\n",
    "            year = '20' + year\n",
    "        return year +'-'+ month +'-'+ day\n",
    "    \n",
    "for index, row in df_franzi.iterrows():\n",
    "    if pd.isna(row['end_date']):\n",
    "        extracted_date = extract_date_after_to_or_on(row['schedule_comment'])\n",
    "        if extracted_date:\n",
    "            df_franzi.at[index, 'end_date'] = extracted_date\n",
    "\n",
    "df_franzi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Der Code zum Filtern von Zeilen, in denen 'start_date' oder 'end_date' 'NaN' ist\n",
    "# und die 'schedule_comment' nicht mit 'Exempt' oder '\\r\\nExempt' beginnen\n",
    "\n",
    "nan_dates_df = df_franzi[\n",
    "    ((df_franzi['end_date'].isna())) & \n",
    "    (~df_franzi['schedule_comment'].str.match(r'^(Exempt|\\r\\nExempt)'))\n",
    "][['start_date', 'end_date', 'schedule_comment']]\n",
    "\n",
    "# Ausgabe des gefilterten DataFrames\n",
    "nan_dates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Der Code zum Filtern von Zeilen, in denen 'start_date' oder 'end_date' 'NaN' ist\n",
    "# und die 'schedule_comment' nicht mit 'Exempt' oder '\\r\\nExempt' beginnen\n",
    "\n",
    "nan_dates_df_start = df_franzi[\n",
    "    ((df_franzi['start_date'].isna())) & \n",
    "    (~df_franzi['schedule_comment'].str.match(r'^(Exempt|\\r\\nExempt)'))\n",
    "][['start_date', 'schedule_comment']]\n",
    "\n",
    "# Ausgabe des gefilterten DataFrames\n",
    "nan_dates_df_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle(\"../data/pickle/cleaned_2021_2023.pkl\")\n",
    "df2 = pd.read_pickle('../data/pickle/cleaned_2018_2020.pkl')\n",
    "df3 = pd.read_pickle('../data/pickle/cleaned_2014-2017.pkl')\n",
    "df4 = pd.read_csv('../data/macro/GDP.csv',encoding='iso-8859-2', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df4, on='year', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"colour_rating\"] = df[\"colour_rating\"].str.lower()\n",
    "\n",
    "# Drop rows where 'project_name' contains 'Unnamed:' followed by other characters\n",
    "df = df[~df['project_name'].str.contains(r'Unnamed:.*', na=False)]\n",
    "\n",
    "# Optionally, reset the index of the cleaned DataFrame\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_start_dates = df.groupby('project_name').apply(lambda x: x.loc[x['year'].idxmax(), 'start_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    latest_start_date = latest_start_dates[row['project_name']]\n",
    "    if pd.isna(row['start_date']) and pd.notna(latest_start_date):\n",
    "        df.at[index, 'start_date'] = latest_start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_benefits = df.groupby('project_name').apply(lambda x: x.loc[x['year'].idxmax(), 'total_benefits'])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    latest_benefit = latest_benefits[row['project_name']]\n",
    "    if pd.isna(row['total_benefits']) and pd.notna(latest_benefit):\n",
    "        df.at[index, 'total_benefits'] = latest_benefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_categories = df.groupby('project_name').apply(lambda x: x.loc[x['year'].idxmax(), 'report_category'])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    latest_category = latest_categories[row['project_name']]\n",
    "    if pd.isna(row['report_category']) and pd.notna(latest_category):\n",
    "        df.at[index, 'report_category'] = latest_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_numbers = df.groupby('project_name').apply(lambda x: x.loc[x['year'].idxmax(), 'project_number'])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    latest_number = latest_numbers[row['project_name']]\n",
    "    if pd.isna(row['project_number']) and pd.notna(latest_number):\n",
    "        df.at[index, 'project_number'] = latest_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description_aims'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_dummies = pd.get_dummies(df, columns=['department', 'colour_rating'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"start_date\"] = pd.to_datetime(df[\"start_date\"])\n",
    "df[\"end_date\"] = pd.to_datetime(df[\"end_date\"])\n",
    "# Calculate the duration in years\n",
    "df[\"year_duration\"] = (df[\"end_date\"] - df[\"start_date\"]).dt.days / 365.25\n",
    "\n",
    "# Optionally, round the duration to a specific number of decimal places\n",
    "df[\"year_duration\"] = df[\"year_duration\"].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_year'] = df['start_date'].dt.year\n",
    "df['end_year'] = df['end_date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add macro data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_columns = pd.read_csv('../data/macro/GDP.csv', encoding='iso-8859-2', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['GDP', 'annual_earning_ft', 'unemployment_rate', 'youth_unemployment_rate', 'inflation_rate', 'population', 'gov_debt', 'tax_revenue', 'revenue_excl_grants', 'grants_and_other_revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(macro_columns, on='year', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/pickle/final_pickle.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['description_aims', 'rating_comment', 'start_date',\n",
    "       'end_date', 'schedule_comment', 'yearly_budget', 'yearly_forecast', 'variance_comment', 'budget_comment',\n",
    "       'report_category', 'project_number', 'total_benefits',\n",
    "       'benefits_comment', 'population', 'revenue_excl_grants', 'grants_and_other_revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colour_rating_columns = [col for col in df.columns if col.startswith('colour_rating_')]\n",
    "# department_columns = [col for col in df.columns if col.startswith('department_')]\n",
    "\n",
    "# def latest_value(df, column):\n",
    "#     try:\n",
    "#         return df.loc[df['year'].idxmax(), column]\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in Group {df.name} for column {column}: {e}\")\n",
    "#         return None\n",
    "\n",
    "agg_dict = {\n",
    "    'wlc_baseline_incl_NCG': 'max',\n",
    "    'year_duration': 'max',\n",
    "    'end_year': 'max',\n",
    "    'start_year': 'min',\n",
    "    'year': 'max',\n",
    "    'GDP': 'mean',\n",
    "    'annual_earning_ft': 'mean',\n",
    "    'unemployment_rate': 'mean',\n",
    "    'youth_unemployment_rate': 'mean',\n",
    "    'inflation_rate': 'mean',\n",
    "    'gov_debt': 'mean',\n",
    "    'tax_revenue': 'mean',\n",
    "    'department_CO': lambda x: x.mode()[0],\n",
    "    'department_CPS': lambda x: x.mode()[0],\n",
    "    'department_DBT': lambda x: x.mode()[0],\n",
    "    'department_DCMS': lambda x: x.mode()[0],\n",
    "    'department_DEFRA': lambda x: x.mode()[0],\n",
    "    'department_DEFRA & DFT': lambda x: x.mode()[0],\n",
    "    'department_DESNZ': lambda x: x.mode()[0],\n",
    "    'department_DFE': lambda x: x.mode()[0],\n",
    "    'department_DFID': lambda x: x.mode()[0],\n",
    "    'department_DFT': lambda x: x.mode()[0],\n",
    "    'department_DHSC': lambda x: x.mode()[0],\n",
    "    'department_DLUHC': lambda x: x.mode()[0],\n",
    "    'department_DSIT': lambda x: x.mode()[0],\n",
    "    'department_DWP': lambda x: x.mode()[0],\n",
    "    'department_FCDO': lambda x: x.mode()[0],\n",
    "    'department_HMLR': lambda x: x.mode()[0],\n",
    "    'department_HMRC': lambda x: x.mode()[0],\n",
    "    'department_HMT': lambda x: x.mode()[0],\n",
    "    'department_HO': lambda x: x.mode()[0],\n",
    "    'department_MOD': lambda x: x.mode()[0],\n",
    "    'department_MOJ': lambda x: x.mode()[0],\n",
    "    'department_NCA': lambda x: x.mode()[0],\n",
    "    'department_NS&I': lambda x: x.mode()[0],\n",
    "    'department_ONS': lambda x: x.mode()[0],\n",
    "    'department_VOA': lambda x: x.mode()[0],\n",
    "    'colour_rating_amber/green': lambda x: x.mode()[0],\n",
    "    'colour_rating_amber/red': lambda x: x.mode()[0],\n",
    "    'colour_rating_green': lambda x: x.mode()[0],\n",
    "    'colour_rating_red': lambda x: x.mode()[0],\n",
    "    'colour_rating_reset': lambda x: x.mode()[0]\n",
    "}\n",
    "\n",
    "# for col in colour_rating_columns:\n",
    "#     agg_dict[col] = lambda x, col=col: latest_value(x, col)\n",
    "\n",
    "# for col in department_columns:\n",
    "#     agg_dict[col] = lambda x, col=col: latest_value(x, col)\n",
    "\n",
    "df = df.groupby('project_name').agg(agg_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['revenue_excl_grants','grants_and_other_revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['year_duration', 'end_year','year', 'youth_unemployment_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = df.drop(columns=['wlc_baseline_incl_NCG'])\n",
    "y = df['wlc_baseline_incl_NCG']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "coefficients = pd.DataFrame({'Feature': X.columns, 'Coefficient': model.coef_})\n",
    "print(coefficients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "X = df.drop(columns=['wlc_baseline_incl_NCG'])\n",
    "y = df['wlc_baseline_incl_NCG']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_reg = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f'Best Params: {best_params}')\n",
    "print(f'Best negative MSE (Training): {best_score}')\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error (Test): {mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mse)\n",
    "print(f'Root Mean Squared Error: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from hyperopt import hp, fmin, tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X = df.drop(columns=['wlc_baseline_incl_NCG'])\n",
    "y = df['wlc_baseline_incl_NCG']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the objective function to minimize\n",
    "def xgb_eval(max_depth, learning_rate, subsample, colsample_bytree):\n",
    "    params = {\n",
    "        'max_depth': int(max_depth),\n",
    "        'learning_rate': learning_rate,\n",
    "        'subsample': subsample,\n",
    "        'colsample_bytree': colsample_bytree,\n",
    "        'n_estimators': 100,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'random_state': 42,\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "# Define the search space\n",
    "pbounds = {\n",
    "    'max_depth': (3, 10),\n",
    "    'learning_rate': (0.01, 0.3),\n",
    "    'subsample': (0.5, 1.0),\n",
    "    'colsample_bytree': (0.5, 1.0),\n",
    "}\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "optimizer = BayesianOptimization(f=xgb_eval, pbounds=pbounds, random_state=42)\n",
    "optimizer.maximize(init_points=5, n_iter=25)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(f\"Best hyperparameters: {optimizer.max['params']}\")\n",
    "print(f\"Best score: {optimizer.max['target']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
